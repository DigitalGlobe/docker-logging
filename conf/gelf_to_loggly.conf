# -*- mode: logstash-conf -*-

# How do you read this file?  See the Logstash docs for the big picture
# https://www.elastic.co/guide/en/logstash/current/config-examples.html

# Input & Output inspired by
# http://www.labouisse.com/how-to/2015/09/14/elk-and-docker-1-8/
input {
    gelf {
        type => docker
    }
}

# Filters inspired by
# http://www.labouisse.com/how-to/2015/09/23/elk-docker-and-spring-boot/
filter {
    # docker run --log-driver=gelf --log-opt tag="nginx" ...
    if [tag] == 'nginx' {
        # Nginx logs are formatted the same as Apache logs.  Use the Apache filter that ships with Logstash
        # https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns#L94
        grok {
            match => { "short_message" => "%{COMBINEDAPACHELOG}" }
        }
        # When the grok filter fails, preserve the log via the `message` field.
        if "_grokparsefailure" in [tags] {
            mutate {
                replace => { "message" => "%{short_message}" }
            }
        }
        else {
            # Type casting for Kibana
            mutate {
                convert => { "bytes" => "integer" }
            }
        }
    }
    # docker run --log-driver=gelf --log-opt tag="postgres" ...
    # Filter taken from https://gist.github.com/bdelbosc/9508821#file-logstash-conf-L13
    else if [tag] == "postgresql" {
        multiline {
            pattern => "^\s"
            what => "previous"
        }
        if "COPY" in [message] { drop {} }
        else if "duration" in [message] {
            if "execute" in [message] {
                mutate { add_tag => ["sql-query"] }
                grok {
                    match => ["message", "%{DATESTAMP:timestamp} CET \[%{POSINT:pid}\]: \[%{POSINT}-1] user=%{NOTSPACE:connection_id} %{WORD:level}:  duration: %{NUMBER:duration_ms} ms  execute %{GREEDYDATA}: %{GREEDYDATA:request}"]
                }
            } else if "parse" in [message] {
                mutate { add_tag => ["sql-parse"] }
                grok {
                    match => ["message", "%{DATESTAMP:timestamp} CET \[%{POSINT:pid}\]: \[%{POSINT}-1] user=%{GREEDYDATA:connection_id} %{WORD:level}:  duration: %{NUMBER:duration_ms} ms  parse %{GREEDYDATA}: %{GREEDYDATA:request}"]
                }
            } else if "bind" in [message] {
                mutate { add_tag => ["sql-bind"] }
                grok {
                    match => ["message", "%{DATESTAMP:timestamp} CET \[%{POSINT:pid}\]: \[%{POSINT}-1] user=%{GREEDYDATA:connection_id} %{WORD:level}:  duration: %{NUMBER:duration_ms} ms  bind %{GREEDYDATA}: %{GREEDYDATA:request}"]
                }
            } else if "statement" in [message] {
                mutate { add_tag => ["sql-query"] }
                grok {
                    match => ["message", "%{DATESTAMP:timestamp} CET \[%{POSINT:pid}\]: \[%{POSINT}-1] user=%{NOTSPACE:connection_id} %{WORD:level}:  duration: %{NUMBER:duration_ms} ms  statement: %{GREEDYDATA:request}"]
                }
            }
            mutate { convert => [ "execution_ms", "float" ] }
            ruby { code => "event['elapsed'] = event['duration_ms'].to_f / 1000" }
        } else {
            mutate { add_tag => "db-message" }
            grok {
                match => ["message", "%{DATESTAMP:timestamp} CET \[%{POSINT:pid}\]: \[%{POSINT}-1] user=%{NOTSPACE:connection_id} %{WORD:level}: %{GREEDYDATA:message}"]
            }
        }
    }
    # docker run --log-driver=gelf --log-opt tag="rails" ...
    else if [tag] == "rails" {
        # Capture multiline Rails logs (All rails logs should begin with "Started ...")
        multiline {
            pattern => "^Started "
            negate => true
            what => "previous"
            source => "short_message"
        }
        # Use the Rails3 filter that ships with Logstash
        # https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/rails
        grok {
            match => { "short_message" => "%{RAILS3}" }
        }
        if "_grokparsefailure" in [tags] {
            mutate {
                replace => { "message" => "%{short_message}" }
            }
        }
        else {
            # Type casting for Kibana
            mutate {
                convert => { "totalms" => "float" }
                convert => { "viewms" => "float" }
                convert => { "activerecordms" => "float" }
            }
        }
    }
}

output {
    loggly {
        key => "LOGGLY_CUSTOMER_TOKEN"
    }
    # If you need to do some testing & debugging, uncomment this line:
    # stdout { codec => rubydebug }
}
